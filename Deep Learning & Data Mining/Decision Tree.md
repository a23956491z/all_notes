---
tags : machine-learning
---

### 決策樹
* 用於分類、回歸的監督式學習
* 從特徵推斷出**多個二分規則**
	* 中間節點(non-leaf node)：測試條件
	* 分支(branch)：條件測試的結果
	* 葉節點(leaf nodes)：最終的分類結果
![](https://i.imgur.com/coSBmAi.png)

產生決策樹：
1. 建立樹狀結構
2. 修剪樹狀結構

決策樹演算法：
* 樹結構由上而下產生，遞回方式建立
* 無法處理連續的數值：需要**離散化**
* 運作
	1. 所有訓練樣本在根節點
	2. 選取屬性，並將樣本分開
	3. 以統計性測量測試屬性
	4. 停止條件：
		* 節點的所有樣本都屬於同一個類別
		* 所有的屬性都用完了，以樣本數最多的類別作爲葉節點
		* 選取了某屬性後，分支完全沒有樣本
* 常用特徵優先
	* 資訊獲利最大化
	* 資訊獲利比最大化
	* 基尼指數最小化


### 資訊獲利

資訊獲利比 = 資訊獲利 / 資訊熵

### 基尼指數
表示資料的不平均程度
所有樣本類別相同，基尼指數爲0


